<launch>
    <node pkg="usb_cam" type="usb_cam_node" name="usb_cam">
        <rosparam>
            pixel_format: yuyv
        </rosparam>
    </node>

    <node pkg="LAVIS_grpc_server" type="rosbridge_server.py" name="LAVIS_grpc_bridge_server"
        output="screen">
    </node>

    <node pkg="LAVIS_grpc_server" type="sample_query_node.py" name="sample_query_node"
        output="screen">
        <remap from="~image" to="/usb_cam/image_raw"/>
        <remap from="~image_captioning" to="/LAVIS_grpc_bridge_server/image_captioning"/>
        <remap from="~visual_question_answering"
            to="/LAVIS_grpc_bridge_server/visual_question_answering"/>
        <remap from="~speech_to_text" to="/speech_to_text"/>
    </node>

    <include file="$(find ros_speech_recognition)/launch/speech_recognition.launch">
        <arg name="continuous" value="true"/>
        <arg name="voice_topic" value="/speech_to_text"/>
        <arg name="language" value="en-US"/>
    </include>
</launch>
